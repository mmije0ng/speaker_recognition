import os
import numpy as np
import sounddevice as sd
from queue import Queue
from collections import deque
from resemblyzer import VoiceEncoder, preprocess_wav
from scipy.spatial.distance import cosine

# ì„¤ì •
SAMPLE_RATE = 16000
FRAME_DURATION = 1  # ì´ˆ ë‹¨ìœ„
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION)
WINDOW_DURATION = 3  # ëˆ„ì  ì‹œê°„ (ì´ˆ)
WINDOW_SIZE = FRAME_SIZE * WINDOW_DURATION
SIMILARITY_THRESHOLD = 0.60
TARGET_SPEAKER = "SPEAKER_01"  # ë¹„êµ ëŒ€ìƒ í™”ìž

def verify_single_speaker(reference_embedding, test_embedding):
    similarity = 1 - cosine(reference_embedding, test_embedding)
    return similarity, similarity > SIMILARITY_THRESHOLD

def list_input_devices():
    print("\nðŸŽ™ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ìž…ë ¥ ìž¥ì¹˜ ëª©ë¡:")
    devices = sd.query_devices()
    for i, device in enumerate(devices):
        if device['max_input_channels'] > 0:
            print(f"  [{i}] {device['name']} ({device['hostapi']})")

def run_verification_against_target(reference_embedding, target_name="Target"):
    encoder = VoiceEncoder()
    q = Queue()
    buffer = deque(maxlen=WINDOW_SIZE)

    list_input_devices()

    default_input = sd.default.device[0]
    if default_input is None or default_input < 0:
        print("\n[!] ìž…ë ¥ ìž¥ì¹˜ê°€ ì„¤ì •ë˜ì–´ ìžˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    else:
        print(f"\nðŸŽ§ ê¸°ë³¸ ìž…ë ¥ ìž¥ì¹˜ ID: {default_input} â€” {sd.query_devices(default_input)['name']}")

    def callback(indata, frames, time, status):
        if status:
            print(f"[!] ë§ˆì´í¬ ìƒíƒœ ê²½ê³ : {status}")
        buffer.extend(indata[:, 0])
        if len(buffer) == WINDOW_SIZE:
            q.put(np.array(buffer))

    with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, blocksize=FRAME_SIZE, callback=callback):
        print(f"\nðŸŽ™ï¸ ì‹¤ì‹œê°„ í™”ìž ê²€ì¦ ì¤‘ â€” ëŒ€ìƒ í™”ìž: {target_name} (3ì´ˆ ëˆ„ì )... (Ctrl+Cë¡œ ì¢…ë£Œ)")
        try:
            while True:
                if not q.empty():
                    audio_data = q.get()
                    test_embedding = encoder.embed_utterance(preprocess_wav(audio_data, SAMPLE_RATE))
                    similarity, is_match = verify_single_speaker(reference_embedding, test_embedding)

                    if is_match:
                        print(f"âœ… ë™ì¼ í™”ìž ({target_name}) â€” ìœ ì‚¬ë„: {similarity:.4f}")
                    else:
                        print(f"âŒ ë‹¤ë¥¸ í™”ìž â€” ìœ ì‚¬ë„: {similarity:.4f}")
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì¢…ë£Œ")

if __name__ == "__main__":
    all_embeddings = np.load("data/reference_multi.npy", allow_pickle=True).item()

    if TARGET_SPEAKER not in all_embeddings:
        print(f"[!] '{TARGET_SPEAKER}' í™”ìžê°€ npyì— ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ðŸ—‚ï¸ ë“±ë¡ëœ í™”ìž ëª©ë¡:")
        for name in all_embeddings:
            print(f" - {name}")
    else:
        print(f"\nðŸŽ¯ ë¹„êµ ëŒ€ìƒ: {TARGET_SPEAKER}")
        target_embedding = all_embeddings[TARGET_SPEAKER]
        run_verification_against_target(target_embedding, target_name=TARGET_SPEAKER)
