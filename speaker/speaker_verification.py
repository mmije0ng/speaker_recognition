import os
import numpy as np
import sounddevice as sd
from queue import Queue
from collections import deque
from resemblyzer import VoiceEncoder, preprocess_wav
from scipy.spatial.distance import cosine

# ì„¤ì •
SAMPLE_RATE = 16000
FRAME_DURATION = 1
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION)
WINDOW_DURATION = 3
WINDOW_SIZE = FRAME_SIZE * WINDOW_DURATION
SIMILARITY_THRESHOLD = 0.60
EMBEDDING_PATH = "data/reference_multi.npy"

def verify_live_speaker(reference_embedding: np.ndarray, threshold: float = SIMILARITY_THRESHOLD) -> bool:
    encoder = VoiceEncoder()
    q = Queue()
    buffer = deque(maxlen=WINDOW_SIZE)

    default_input = sd.default.device[0]

    def callback(indata, frames, time, status):
        if status:
            print(f"[!] ë§ˆì´í¬ ìƒíƒœ ê²½ê³ : {status}")
        buffer.extend(indata[:, 0])
        if len(buffer) >= WINDOW_SIZE:
            q.put(np.array(buffer))

    with sd.InputStream(
        device=default_input,
        channels=1,
        dtype='float32',
        samplerate=SAMPLE_RATE,
        blocksize=FRAME_SIZE,
        callback=callback):
        
        print(f"\nğŸ™ï¸ ì‹¤ì‹œê°„ í™”ì ê²€ì¦ì„ ìœ„í•´ {WINDOW_DURATION}ì´ˆê°„ ë§í•´ì£¼ì„¸ìš”... (Ctrl+Cë¡œ ì¢…ë£Œ)")
        try:
            while True:
                if not q.empty():
                    audio_chunk = q.get()
                    processed = preprocess_wav(audio_chunk, SAMPLE_RATE)
                    test_embedding = encoder.embed_utterance(processed)
                    similarity = 1 - cosine(reference_embedding, test_embedding)
                    print(f"ğŸ§ª ìœ ì‚¬ë„: {similarity:.4f}")
                    return similarity > threshold
        except KeyboardInterrupt:
            print("â¹ï¸ ì¤‘ë‹¨ë¨")
            return False

def verify_speaker_by_name(speaker_name: str, embeddings_path: str = EMBEDDING_PATH) -> bool:
    if not os.path.exists(embeddings_path):
        print(f"[!] ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {embeddings_path}")
        return False

    embeddings = np.load(embeddings_path, allow_pickle=True).item()

    if speaker_name not in embeddings:
        print(f"[!] '{speaker_name}' í™”ìëŠ” ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ğŸ—‚ï¸ ë“±ë¡ëœ í™”ì ëª©ë¡:")
        for name in embeddings:
            print(f" - {name}")
        return False

    print(f"\nğŸ¯ ë¹„êµ ëŒ€ìƒ í™”ì: {speaker_name}")
    reference_embedding = embeddings[speaker_name]
    return verify_live_speaker(reference_embedding)

if __name__ == "__main__":
    TARGET_SPEAKER = "ë°•ë¯¸ì •"  # í™•ì¸ ëŒ€ìƒ í™”ì

    result = verify_speaker_by_name(TARGET_SPEAKER)

    if result:
        print(f"\nâœ… ë™ì¼ í™”ìë¡œ ê²€ì¦ë¨: {TARGET_SPEAKER} (True)")
    else:
        print(f"\nâŒ ë™ì¼ í™”ìê°€ ì•„ë‹˜: {TARGET_SPEAKER} (False)")
