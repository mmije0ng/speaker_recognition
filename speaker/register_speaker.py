import os
import numpy as np
import torch
import sounddevice as sd
from scipy.io.wavfile import write
from resemblyzer import VoiceEncoder, preprocess_wav
from pydub import AudioSegment
from dotenv import load_dotenv

load_dotenv()

# ì„¤ì •
SAMPLE_RATE = 16000
RECORD_SECONDS = 5  # ë…¹ìŒ ì‹œê°„ (ì´ˆ)
OUTPUT_DIR = "data/speakers_wav"
EMBEDDING_PATH = "data/reference_multi.npy"

os.makedirs(OUTPUT_DIR, exist_ok=True)

def record_audio(filename: str):
    print(f"\nğŸ™ï¸ '{filename}' ìŒì„± ë…¹ìŒ ì‹œì‘ ({RECORD_SECONDS}ì´ˆ)...")
    audio = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='int16')
    sd.wait()
    write(filename, SAMPLE_RATE, audio)
    print(f"âœ… ë…¹ìŒ ì™„ë£Œ: {filename}")

def register_speaker(speaker_name: str):
    encoder = VoiceEncoder()
    
    wav_path = os.path.join(OUTPUT_DIR, f"{speaker_name}.wav")
    record_audio(wav_path)
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬
    audio = AudioSegment.from_wav(wav_path)
    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0
    if audio.channels == 2:
        samples = samples.reshape((-1, 2)).mean(axis=1)

    preprocessed = preprocess_wav(samples, SAMPLE_RATE)
    embedding = encoder.embed_utterance(preprocessed)

    # ê¸°ì¡´ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(EMBEDDING_PATH):
        embeddings = np.load(EMBEDDING_PATH, allow_pickle=True).item()
    else:
        embeddings = {}

    # ì €ì¥
    embeddings[speaker_name] = embedding
    np.save(EMBEDDING_PATH, embeddings)
    print(f"ğŸ’¾ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: '{speaker_name}' â†’ {EMBEDDING_PATH}")

if __name__ == "__main__":
    speaker_name = input("\në“±ë¡í•  í™”ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if speaker_name:
        register_speaker(speaker_name)
    else:
        print("â— í™”ì ì´ë¦„ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
